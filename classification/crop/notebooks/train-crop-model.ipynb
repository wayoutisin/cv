{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch_summary","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:58:52.855272Z","iopub.execute_input":"2022-04-13T13:58:52.855635Z","iopub.status.idle":"2022-04-13T13:59:01.634218Z","shell.execute_reply.started":"2022-04-13T13:58:52.855527Z","shell.execute_reply":"2022-04-13T13:59:01.633404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nimport warnings\nwarnings.simplefilter('ignore')\nimport numpy as np\nimport torchvision\nimport torch.nn as nn\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\nimport matplotlib.pyplot as plt\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torchvision.models as models\n\nimport imgaug as ia\nimport imgaug.augmenters as iaa\nfrom collections import Counter\nfrom torchsummary import summary","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-13T13:59:01.638445Z","iopub.execute_input":"2022-04-13T13:59:01.638773Z","iopub.status.idle":"2022-04-13T13:59:04.904316Z","shell.execute_reply.started":"2022-04-13T13:59:01.638743Z","shell.execute_reply":"2022-04-13T13:59:04.903575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_DIR = '../input/cropdata/input/train/'\nTEST_DIR = '../input/cropdata/input/train/'\nVALIDATE_DIR = '../input/cropdata/input/train/'\nBATCH_SIZE = 64","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:59:04.905945Z","iopub.execute_input":"2022-04-13T13:59:04.906203Z","iopub.status.idle":"2022-04-13T13:59:04.91129Z","shell.execute_reply.started":"2022-04-13T13:59:04.906169Z","shell.execute_reply":"2022-04-13T13:59:04.910504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:59:04.91368Z","iopub.execute_input":"2022-04-13T13:59:04.913948Z","iopub.status.idle":"2022-04-13T13:59:04.971684Z","shell.execute_reply.started":"2022-04-13T13:59:04.913895Z","shell.execute_reply":"2022-04-13T13:59:04.970951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data","metadata":{}},{"cell_type":"code","source":"class CropDataset(Dataset):\n    def __init__(self, file_path, transform=None, augment=False):\n        xform = transforms.Compose([transforms.ToTensor()]) if transform is None else transform\n        self.img_dataset = datasets.ImageFolder(file_path, transform=xform)\n        self.aug = augment\n        \n        ## augumentation initialization\n        ia.seed(241)\n\n        self.seq = iaa.Sequential([\n            iaa.Fliplr(0.5), # horizontal flips\n            iaa.Crop(percent=(0, 0.1)), # random crops\n            # Small gaussian blur with random sigma between 0 and 0.5.\n            # But we only blur about 50% of all images.\n            iaa.Sometimes(\n                0.5,\n                iaa.GaussianBlur(sigma=(0, 0.5))\n            ),\n            # Strengthen or weaken the contrast in each image.\n            iaa.LinearContrast((0.75, 1.5)),\n                        \n            # Make some images brighter and some darker.\n            # In 20% of all cases, we sample the multiplier once per channel,\n            # which can end up changing the color of the images.\n            iaa.Multiply((0.8, 1.2), per_channel=0.2),\n            # Apply affine transformations to each image.\n            # Scale/zoom them, translate/move them, rotate them and shear them.\n            iaa.Affine(\n                scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n                translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n                rotate=(-25, 25),\n                shear=(-8, 8)\n            )\n        ], random_order=True) # apply augmenters in random order\n\n    def __len__(self):\n        return len(self.img_dataset)\n\n    def __getitem__(self, idx):\n        image, label = self.img_dataset[idx]\n        return image, label\n    \n    # this is an experimental method created to explore how the dunder methods can be modified\n    def __repr__(self, idx=0):\n        image, label = self.img_dataset[idx]\n        plt.imshow(image.permute(1,2,0))\n        return str(\"Display view of the image\")\n    \n    def collate_fn(self, batch):\n        images, targets = list(zip(*batch))\n        images = torch.stack(images).permute(0 , 2, 3, 1)\n        if self.aug: images=self.seq.augment_images(images=images.numpy()) \n        targets = torch.tensor(targets)\n        images = torch.tensor(images).permute(0, 3, 1, 2)\n        if torch.cuda.is_available():\n            targets = targets.to(device)\n            images = images.to(device)\n        return images, targets","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:59:04.975241Z","iopub.execute_input":"2022-04-13T13:59:04.975697Z","iopub.status.idle":"2022-04-13T13:59:04.990434Z","shell.execute_reply.started":"2022-04-13T13:59:04.975657Z","shell.execute_reply":"2022-04-13T13:59:04.989614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Train Data","metadata":{}},{"cell_type":"code","source":"# Here we create our final transformation that would be used before we send the data for training the model\ntransform = torchvision.transforms.Compose([transforms.ToTensor(),\n                                            transforms.Normalize((0.4743617, 0.49847862, 0.4265874 ),\n                                                                 (0.21134755, 0.19044809, 0.22679578))]\n                                          )\ncrop_dataset = CropDataset(TRAIN_DIR, transform, True)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:59:04.991632Z","iopub.execute_input":"2022-04-13T13:59:04.991862Z","iopub.status.idle":"2022-04-13T13:59:08.850323Z","shell.execute_reply.started":"2022-04-13T13:59:04.991833Z","shell.execute_reply":"2022-04-13T13:59:08.849601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define a weighted sampler for the images \nnum_samples = len(crop_dataset.img_dataset)\nlabel = list(crop_dataset.img_dataset.targets)\nclass_weights = [round(1.0/v,5) for k, v in dict(Counter(crop_dataset.img_dataset.targets)).items()]\nweights = [class_weights[label[i]] for i in range(num_samples)]\n\n# Now we can create a loader that will help us load images in batches for training purpose \nsampler = WeightedRandomSampler(weights, num_samples, replacement=True)\ncrop_loader = DataLoader(dataset=crop_dataset.img_dataset, \n                         batch_size=BATCH_SIZE, \n                         sampler=sampler, \n                         #collate_fn=crop_dataset.collate_fn\n                        )","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:59:08.85253Z","iopub.execute_input":"2022-04-13T13:59:08.852963Z","iopub.status.idle":"2022-04-13T13:59:08.866176Z","shell.execute_reply.started":"2022-04-13T13:59:08.852928Z","shell.execute_reply":"2022-04-13T13:59:08.865527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Test Data","metadata":{}},{"cell_type":"code","source":"test_dataset = CropDataset(TEST_DIR, transform, True)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:59:08.867253Z","iopub.execute_input":"2022-04-13T13:59:08.867892Z","iopub.status.idle":"2022-04-13T13:59:08.957563Z","shell.execute_reply.started":"2022-04-13T13:59:08.867845Z","shell.execute_reply":"2022-04-13T13:59:08.956906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loader = DataLoader(dataset=test_dataset.img_dataset, \n                         batch_size=BATCH_SIZE, \n                         shuffle= True\n                         #collate_fn=crop_dataset.collate_fn\n                        )","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:59:08.95987Z","iopub.execute_input":"2022-04-13T13:59:08.960446Z","iopub.status.idle":"2022-04-13T13:59:08.964695Z","shell.execute_reply.started":"2022-04-13T13:59:08.9604Z","shell.execute_reply":"2022-04-13T13:59:08.963792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Validate Data","metadata":{}},{"cell_type":"code","source":"valid_dataset = CropDataset(VALIDATE_DIR, transform, True)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:59:08.968194Z","iopub.execute_input":"2022-04-13T13:59:08.968663Z","iopub.status.idle":"2022-04-13T13:59:09.052086Z","shell.execute_reply.started":"2022-04-13T13:59:08.968632Z","shell.execute_reply":"2022-04-13T13:59:09.051491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_loader = DataLoader(dataset=valid_dataset.img_dataset, \n                         batch_size=BATCH_SIZE, \n                         shuffle= True\n                         #collate_fn=crop_dataset.collate_fn\n                        )","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:59:09.05319Z","iopub.execute_input":"2022-04-13T13:59:09.053722Z","iopub.status.idle":"2022-04-13T13:59:09.05828Z","shell.execute_reply.started":"2022-04-13T13:59:09.053685Z","shell.execute_reply":"2022-04-13T13:59:09.057361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Initialize","metadata":{}},{"cell_type":"code","source":"def train_model(model, n_epochs, data_loader):\n    train_epochs, train_loss, train_accuracy = [], [], []\n    for epoch in range(n_epochs):  # loop over the dataset multiple times\n        running_loss = 0.0\n        total = 0\n        correct = 0\n        model.train()\n        for i, data in enumerate(data_loader, 0):\n            if (torch.cuda.is_available()):\n                inputs, labels = data[0].to(device), data[1].to(device)\n            else:\n                inputs, labels = data\n            optimizer.zero_grad()\n\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            # print statistics\n            running_loss += loss.item()\n\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n\n            if i % 100 == 0 and i > 0:    \n                accu=100.*correct/total\n                mloss=running_loss / 100.\n                print(f'[{epoch + 1}, {i + 1:5d}] loss: {mloss:.3f} accuracy:{accu:.3f}')\n                train_epochs.append(epoch + 1)\n                train_loss.append(mloss)\n                train_accuracy.append(accu)\n                running_loss = 0.0\n    print('Finished Training')\n    return train_epochs, train_loss, train_accuracy","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:59:09.059438Z","iopub.execute_input":"2022-04-13T13:59:09.059822Z","iopub.status.idle":"2022-04-13T13:59:09.071194Z","shell.execute_reply.started":"2022-04-13T13:59:09.059787Z","shell.execute_reply":"2022-04-13T13:59:09.07052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_accuracy(model, data_loader):\n    correct = 0\n    total = 0\n    # since we're not training, we don't need to calculate the gradients for our outputs\n    with torch.no_grad():\n        for data in data_loader:\n            images, labels = data[0].to(device), data[1].to(device)\n            # calculate outputs by running images through the network\n            outputs = model(images)\n            # the class with the highest energy is what we choose as prediction\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    accuracy = 100 * correct // total\n    print(f'Accuracy of the network on the test images: {accuracy} %')\n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:59:09.072359Z","iopub.execute_input":"2022-04-13T13:59:09.072806Z","iopub.status.idle":"2022-04-13T13:59:09.083575Z","shell.execute_reply.started":"2022-04-13T13:59:09.072773Z","shell.execute_reply":"2022-04-13T13:59:09.082905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_class_accuracy(model, dataset, data_loader):\n    # prepare to count predictions for each class\n    correct_pred = {value:0 for key, value in dataset.img_dataset.class_to_idx.items()}\n    total_pred = {value:0 for key, value in dataset.img_dataset.class_to_idx.items()}\n\n    # again no gradients needed\n    with torch.no_grad():\n        for data in data_loader:\n            images, labels = data[0].to(device), data[1].to(device)\n            outputs = model(images)\n            _, predictions = torch.max(outputs, 1)\n            # collect the correct predictions for each class\n            for label, prediction in zip(labels, predictions):\n                if label == prediction:\n                    correct_pred[int(label)] += 1\n                total_pred[int(label)] += 1\n\n    accuracy_per_class = {}\n    # print accuracy for each class\n    for key, correct_count in correct_pred.items():\n        accuracy = 100 * float(correct_count) / total_pred[key]\n        print(f'Accuracy for class: {key:5d} is {accuracy:.1f} %')\n        accuracy_per_class[key] = accuracy\n    \n    return accuracy_per_class","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:59:09.086382Z","iopub.execute_input":"2022-04-13T13:59:09.086818Z","iopub.status.idle":"2022-04-13T13:59:09.096319Z","shell.execute_reply.started":"2022-04-13T13:59:09.086777Z","shell.execute_reply":"2022-04-13T13:59:09.095601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Custom Model","metadata":{}},{"cell_type":"code","source":"# Now create a a model that can be trained for disease detection\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 9)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 12, 6)\n        self.conv3 = nn.Conv2d(12, 18, 3)\n        self.fc1 = nn.Linear(18 * 28 * 28, 4096)\n        self.fc2 = nn.Linear(4096, 1024)\n        self.fc3 = nn.Linear(1024, 512)\n        self.fc4 = nn.Linear(512, 38)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = self.pool(F.relu(self.conv3(x)))\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        x = self.fc4(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:59:09.099359Z","iopub.execute_input":"2022-04-13T13:59:09.099918Z","iopub.status.idle":"2022-04-13T13:59:09.109202Z","shell.execute_reply.started":"2022-04-13T13:59:09.099885Z","shell.execute_reply":"2022-04-13T13:59:09.108522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"net = Net()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\nif(torch.cuda.is_available()):\n    net.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:59:09.11057Z","iopub.execute_input":"2022-04-13T13:59:09.111253Z","iopub.status.idle":"2022-04-13T13:59:12.527809Z","shell.execute_reply.started":"2022-04-13T13:59:09.111218Z","shell.execute_reply":"2022-04-13T13:59:12.527034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cust_epochs, cust_loss, cust_accuracy = train_model(net, 10, crop_loader)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:59:12.529161Z","iopub.execute_input":"2022-04-13T13:59:12.529412Z","iopub.status.idle":"2022-04-13T14:07:44.512358Z","shell.execute_reply.started":"2022-04-13T13:59:12.52938Z","shell.execute_reply":"2022-04-13T14:07:44.511615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.ticker as mtick\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mticker\n%matplotlib inline\n\nplt.subplot(211)\nplt.plot(cust_epochs, cust_loss, 'bo', label='Training loss')\nplt.title('Training loss (Custom Model)')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.grid('off')\nplt.show()\n\nplt.subplot(212)\nplt.plot(cust_epochs, cust_accuracy, 'r', label='Training accuracy')\nplt.title('Training accuracy (Custom Model)')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.grid('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T14:07:44.517019Z","iopub.execute_input":"2022-04-13T14:07:44.517285Z","iopub.status.idle":"2022-04-13T14:07:44.862093Z","shell.execute_reply.started":"2022-04-13T14:07:44.517249Z","shell.execute_reply":"2022-04-13T14:07:44.861434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test Custom Model","metadata":{}},{"cell_type":"code","source":"cust_test_accuracy = compute_accuracy(net, test_loader)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T14:07:44.863146Z","iopub.execute_input":"2022-04-13T14:07:44.863519Z","iopub.status.idle":"2022-04-13T14:08:23.366023Z","shell.execute_reply.started":"2022-04-13T14:07:44.863484Z","shell.execute_reply":"2022-04-13T14:08:23.365286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cust_test_accuracy_per_class = compute_class_accuracy(net, test_dataset, test_loader)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T14:08:23.367417Z","iopub.execute_input":"2022-04-13T14:08:23.367863Z","iopub.status.idle":"2022-04-13T14:09:02.328276Z","shell.execute_reply.started":"2022-04-13T14:08:23.367824Z","shell.execute_reply":"2022-04-13T14:09:02.327539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Validate Custom Model","metadata":{}},{"cell_type":"code","source":"cust_valid_accuracy = compute_accuracy(net, valid_loader)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T14:09:02.329703Z","iopub.execute_input":"2022-04-13T14:09:02.329964Z","iopub.status.idle":"2022-04-13T14:09:40.727915Z","shell.execute_reply.started":"2022-04-13T14:09:02.329929Z","shell.execute_reply":"2022-04-13T14:09:40.727204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cust_valid_accuracy_per_class = compute_class_accuracy(net, valid_dataset, valid_loader)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T14:09:40.729213Z","iopub.execute_input":"2022-04-13T14:09:40.729634Z","iopub.status.idle":"2022-04-13T14:10:20.104049Z","shell.execute_reply.started":"2022-04-13T14:09:40.729597Z","shell.execute_reply":"2022-04-13T14:10:20.103342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Transfer Learning - VGG","metadata":{}},{"cell_type":"code","source":"def vgg_model():\n    \n    # initialize a vgg model\n    vgg_model = models.vgg16(pretrained=True)\n    \n    # freeze all the parameters in the sequentional layer\n    for param in vgg_model.parameters():\n        param.requires_grad = False\n    \n    # change the average pool layer\n    vgg_model.avgpool = nn.AdaptiveAvgPool2d(output_size=(7,7))\n\n    # Change the Classifier layer\n    vgg_model.classifier = nn.Sequential(nn.Flatten(),\n                                    nn.Linear(25088, 4096),\n                                    nn.ReLU(),\n                                    nn.Dropout(0.2),\n                                    nn.Linear(4096, 512),\n                                    nn.ReLU(),\n                                    nn.Dropout(0.2),\n                                    nn.Linear(512, 34))\n    return vgg_model","metadata":{"execution":{"iopub.status.busy":"2022-04-13T14:10:20.105332Z","iopub.execute_input":"2022-04-13T14:10:20.105596Z","iopub.status.idle":"2022-04-13T14:10:20.112241Z","shell.execute_reply.started":"2022-04-13T14:10:20.105542Z","shell.execute_reply":"2022-04-13T14:10:20.111503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16 = vgg_model()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)\nif(torch.cuda.is_available()):\n    vgg16 = vgg16.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T14:10:20.113653Z","iopub.execute_input":"2022-04-13T14:10:20.114008Z","iopub.status.idle":"2022-04-13T14:10:57.79535Z","shell.execute_reply.started":"2022-04-13T14:10:20.113973Z","shell.execute_reply":"2022-04-13T14:10:57.794602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary(vgg16, torch.zeros(1,3,224,224))","metadata":{"execution":{"iopub.status.busy":"2022-04-13T14:10:57.796474Z","iopub.execute_input":"2022-04-13T14:10:57.796735Z","iopub.status.idle":"2022-04-13T14:10:57.828654Z","shell.execute_reply.started":"2022-04-13T14:10:57.796702Z","shell.execute_reply":"2022-04-13T14:10:57.82786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg_epochs, vgg_loss, vgg_accuracy = train_model(vgg16, 5,crop_loader)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T14:10:57.829778Z","iopub.execute_input":"2022-04-13T14:10:57.8304Z","iopub.status.idle":"2022-04-13T14:18:33.112749Z","shell.execute_reply.started":"2022-04-13T14:10:57.830362Z","shell.execute_reply":"2022-04-13T14:18:33.111957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplot(211)\nplt.plot(vgg_epochs, vgg_loss, 'bo', label='Training loss')\nplt.title('Training loss (VGG)')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.grid('off')\nplt.show()\n\nplt.subplot(212)\nplt.plot(vgg_epochs, vgg_accuracy, 'r', label='Training accuracy')\nplt.title('Training accuracy (VGG)')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.grid('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T14:18:33.114069Z","iopub.execute_input":"2022-04-13T14:18:33.114474Z","iopub.status.idle":"2022-04-13T14:18:33.475009Z","shell.execute_reply.started":"2022-04-13T14:18:33.114435Z","shell.execute_reply":"2022-04-13T14:18:33.474364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test VGG","metadata":{}},{"cell_type":"code","source":"vgg_test_accuracy = compute_accuracy(vgg16, test_loader)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T14:18:33.478771Z","iopub.execute_input":"2022-04-13T14:18:33.478958Z","iopub.status.idle":"2022-04-13T14:19:56.34742Z","shell.execute_reply.started":"2022-04-13T14:18:33.478934Z","shell.execute_reply":"2022-04-13T14:19:56.346623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg_test_accuracy_per_class = compute_class_accuracy(vgg16, test_dataset, test_loader)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T14:19:56.348675Z","iopub.execute_input":"2022-04-13T14:19:56.349128Z","iopub.status.idle":"2022-04-13T14:21:15.341595Z","shell.execute_reply.started":"2022-04-13T14:19:56.349083Z","shell.execute_reply":"2022-04-13T14:21:15.340827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Validate VGG","metadata":{}},{"cell_type":"code","source":"vgg_valid_accuracy= compute_accuracy(vgg16, valid_loader)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T14:21:15.342817Z","iopub.execute_input":"2022-04-13T14:21:15.34306Z","iopub.status.idle":"2022-04-13T14:22:34.081589Z","shell.execute_reply.started":"2022-04-13T14:21:15.343027Z","shell.execute_reply":"2022-04-13T14:22:34.080854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg_valid_accuracy_per_class = compute_class_accuracy(vgg16, valid_dataset, valid_loader)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T14:22:34.082998Z","iopub.execute_input":"2022-04-13T14:22:34.083407Z","iopub.status.idle":"2022-04-13T14:23:55.749999Z","shell.execute_reply.started":"2022-04-13T14:22:34.083371Z","shell.execute_reply":"2022-04-13T14:23:55.749268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"### Transfer Learning - ResNet","metadata":{}},{"cell_type":"code","source":"def resnet_model():\n    \n    # initialize a vgg model\n    resnet_model = models.resnet18(pretrained=True)\n    \n    # freeze all the parameters in the sequentional layer\n    for param in resnet_model.parameters():\n        param.requires_grad = False\n    \n    # change the average pool layer\n    resnet_model.avgpool = nn.AdaptiveAvgPool2d(output_size=(3,3))\n\n    # Change the Classifier layer\n    resnet_model.fc = nn.Sequential(nn.Flatten(),\n                                    nn.Linear(4608, 512),\n                                    nn.ReLU(),\n                                    nn.Dropout(0.2),\n                                    nn.Linear(512, 128),\n                                    nn.ReLU(),\n                                    nn.Dropout(0.2),\n                                    nn.Linear(128, 34),\n                                    \n                                    )\n    return resnet_model","metadata":{"execution":{"iopub.status.busy":"2022-04-13T14:23:55.75132Z","iopub.execute_input":"2022-04-13T14:23:55.751581Z","iopub.status.idle":"2022-04-13T14:23:55.759164Z","shell.execute_reply.started":"2022-04-13T14:23:55.751531Z","shell.execute_reply":"2022-04-13T14:23:55.758453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res18 = resnet_model()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(res18.parameters(), lr=0.001, momentum=0.9)\nif(torch.cuda.is_available()):\n    res18 = res18.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T14:23:55.760459Z","iopub.execute_input":"2022-04-13T14:23:55.760887Z","iopub.status.idle":"2022-04-13T14:24:00.4415Z","shell.execute_reply.started":"2022-04-13T14:23:55.76085Z","shell.execute_reply":"2022-04-13T14:24:00.440762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary(res18, torch.zeros(1,3,224,224))","metadata":{"execution":{"iopub.status.busy":"2022-04-13T14:24:00.442684Z","iopub.execute_input":"2022-04-13T14:24:00.443404Z","iopub.status.idle":"2022-04-13T14:24:00.477269Z","shell.execute_reply.started":"2022-04-13T14:24:00.443351Z","shell.execute_reply":"2022-04-13T14:24:00.476617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet_epochs, resnet_loss, resnet_accuracy = train_model(res18, 10,crop_loader)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T14:24:00.478388Z","iopub.execute_input":"2022-04-13T14:24:00.479115Z","iopub.status.idle":"2022-04-13T14:31:32.69678Z","shell.execute_reply.started":"2022-04-13T14:24:00.479079Z","shell.execute_reply":"2022-04-13T14:31:32.695309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplot(211)\nplt.plot(resnet_epochs, resnet_loss, 'bo', label='Training loss')\nplt.title('Training loss (ResNet)')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.grid('off')\nplt.show()\n\nplt.subplot(212)\nplt.plot(resnet_epochs, resnet_accuracy, 'r', label='Training accuracy')\nplt.title('Training accuracy (ResNet)')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.grid('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T14:31:32.697922Z","iopub.execute_input":"2022-04-13T14:31:32.698955Z","iopub.status.idle":"2022-04-13T14:31:33.129485Z","shell.execute_reply.started":"2022-04-13T14:31:32.698913Z","shell.execute_reply":"2022-04-13T14:31:33.128704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test - ResNet","metadata":{}},{"cell_type":"code","source":"resnet_test_accuracy = compute_accuracy(res18, test_loader)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T14:31:33.133451Z","iopub.execute_input":"2022-04-13T14:31:33.133722Z","iopub.status.idle":"2022-04-13T14:32:14.472782Z","shell.execute_reply.started":"2022-04-13T14:31:33.133689Z","shell.execute_reply":"2022-04-13T14:32:14.472004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"restnet_test_accuracy_per_class = compute_class_accuracy(res18, test_dataset, test_loader)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T14:32:14.474074Z","iopub.execute_input":"2022-04-13T14:32:14.474489Z","iopub.status.idle":"2022-04-13T14:32:56.539047Z","shell.execute_reply.started":"2022-04-13T14:32:14.474452Z","shell.execute_reply":"2022-04-13T14:32:56.538331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Validate - ResNet","metadata":{}},{"cell_type":"code","source":"resnet_valid_accuracy= compute_accuracy(res18, valid_loader)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T14:32:56.540281Z","iopub.execute_input":"2022-04-13T14:32:56.540559Z","iopub.status.idle":"2022-04-13T14:33:37.991541Z","shell.execute_reply.started":"2022-04-13T14:32:56.540522Z","shell.execute_reply":"2022-04-13T14:33:37.990015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet_valid_accuracy_per_class = compute_class_accuracy(res18, valid_dataset, valid_loader)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T14:33:37.992817Z","iopub.execute_input":"2022-04-13T14:33:37.993181Z","iopub.status.idle":"2022-04-13T14:34:20.562696Z","shell.execute_reply.started":"2022-04-13T14:33:37.993142Z","shell.execute_reply":"2022-04-13T14:34:20.561973Z"},"trusted":true},"execution_count":null,"outputs":[]}]}