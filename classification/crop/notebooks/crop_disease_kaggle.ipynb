{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T17:32:26.967765Z",
     "iopub.status.busy": "2022-02-19T17:32:26.967184Z",
     "iopub.status.idle": "2022-02-19T17:32:28.483939Z",
     "shell.execute_reply": "2022-02-19T17:32:28.483214Z",
     "shell.execute_reply.started": "2022-02-19T17:32:26.967667Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-18T11:40:09.035907Z",
     "iopub.status.busy": "2022-02-18T11:40:09.03562Z",
     "iopub.status.idle": "2022-02-18T11:41:49.329054Z",
     "shell.execute_reply": "2022-02-18T11:41:49.327854Z",
     "shell.execute_reply.started": "2022-02-18T11:40:09.035875Z"
    }
   },
   "outputs": [],
   "source": [
    "# While training a CNN model we may need to transform the input image data by normalizing it. Normalizing is the \n",
    "# process of creating a standard distribution (x - mean)/std. Typically on web you will see some standard values \n",
    "# being used for normalizing e.g. torch.transforms.Normalize((0.5,0.5,05.),(0.5,0.5,0.5)). Here the first vector \n",
    "# is the mean for R, G, B channels and second vector is the standard deviation for R, G, B channel. If the input \n",
    "# data is in the range 0-1, the above transformation will change it between the range -1 to 1 e.g. (0 - 0.5)/0.5\n",
    "# and (1 - 0.5)/0.5\n",
    "\n",
    "# Do we need to normalize our data?\n",
    "img_loader = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder('../input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train',\n",
    "                                                                         transform=transforms.ToTensor()), \\\n",
    "                                         batch_size=64, \\\n",
    "                                         shuffle=False, \\\n",
    "                                         num_workers=4)\n",
    "\n",
    "first_batch = iter(img_loader).next()\n",
    "feature, label = first_batch\n",
    "print(f'Min pixel value {feature[:1,:,:].min()}')\n",
    "print(f'Max pixel value {feature[:1,:,:].max()}')\n",
    "\n",
    "\n",
    "# From the output you can see that our data is between 0 and 1. The reason the data is between 0 & 1 is because\n",
    "# we have used a tansform torch.transform.ToTensor which converts the input data in range 0-255 to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-18T11:55:35.735622Z",
     "iopub.status.busy": "2022-02-18T11:55:35.735292Z",
     "iopub.status.idle": "2022-02-18T12:00:57.077466Z",
     "shell.execute_reply": "2022-02-18T12:00:57.076334Z",
     "shell.execute_reply.started": "2022-02-18T11:55:35.735587Z"
    }
   },
   "outputs": [],
   "source": [
    "# To normalize our data we need to find the mean and standard deviation for each of the channel. We will use \n",
    "# the existing data to identify these values. Although we would like to find the mean and standard deviation in\n",
    "# a single go using all the records, however we have 70k+ records which may be too large to fit into a single batch\n",
    "# As such we are using the batch size of 4096. At the end we will find a mean of mean and mean of standard deviation\n",
    "\n",
    "img_loader = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder('../input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train',\n",
    "                                                                         transform=transforms.ToTensor()), \\\n",
    "                                         batch_size=1024, \\\n",
    "                                         shuffle=False, \\\n",
    "                                         num_workers=4)\n",
    "\n",
    "pop_mean = []\n",
    "pop_std0 = []\n",
    "pop_std1 = []\n",
    "for i, data in enumerate(img_loader, 0):\n",
    "    numpy_image = data[0].numpy()\n",
    "    \n",
    "    # The axis here represents that we are first going to find the mean across the rows (2), then the columns (3)\n",
    "    # and finally across all the images. Eventually we will get one value for each channel\n",
    "    batch_mean = np.mean(numpy_image, axis=(0,2,3))\n",
    "    batch_std0 = np.std(numpy_image, axis=(0,2,3))\n",
    "    batch_std1 = np.std(numpy_image, axis=(0,2,3), ddof=1) # This is for the degree of freedom N-1\n",
    "    \n",
    "    pop_mean.append(batch_mean)\n",
    "    pop_std0.append(batch_std0)\n",
    "    pop_std1.append(batch_std1)\n",
    "\n",
    "pop_mean = np.array(pop_mean).mean(axis=0)\n",
    "pop_std0 = np.array(pop_std0).mean(axis=0)\n",
    "pop_std1 = np.array(pop_std1).mean(axis=0)\n",
    "\n",
    "print(pop_mean)\n",
    "print(pop_std0)\n",
    "print(pop_std1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T16:45:49.164787Z",
     "iopub.status.busy": "2022-02-19T16:45:49.164511Z",
     "iopub.status.idle": "2022-02-19T16:47:03.924571Z",
     "shell.execute_reply": "2022-02-19T16:47:03.923819Z",
     "shell.execute_reply.started": "2022-02-19T16:45:49.164747Z"
    }
   },
   "outputs": [],
   "source": [
    "# Here we create our final transformation that would be used before we send the data for training the model\n",
    "transform = torchvision.transforms.Compose([transforms.ToTensor(), \\\n",
    "                                            transforms.Normalize((0.4743617, 0.49847862, 0.4265874 ), \\\n",
    "                                                                 (0.21134755, 0.19044809, 0.22679578))\n",
    "                                           ]\n",
    "                                          )\n",
    "crop_dataset = torchvision.datasets.ImageFolder('../input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train', transform=transform)\n",
    "crop_dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T10:06:32.35091Z",
     "iopub.status.busy": "2022-02-19T10:06:32.350185Z",
     "iopub.status.idle": "2022-02-19T10:06:32.355553Z",
     "shell.execute_reply": "2022-02-19T10:06:32.354575Z",
     "shell.execute_reply.started": "2022-02-19T10:06:32.350868Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now we can create a loader that will help us load images in batches for training purpose \n",
    "crop_loader = DataLoader(crop_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-18T12:32:16.82668Z",
     "iopub.status.busy": "2022-02-18T12:32:16.826425Z",
     "iopub.status.idle": "2022-02-18T12:32:45.976359Z",
     "shell.execute_reply": "2022-02-18T12:32:45.973921Z",
     "shell.execute_reply.started": "2022-02-18T12:32:16.82665Z"
    }
   },
   "outputs": [],
   "source": [
    "feature, label = iter(crop_loader).next()\n",
    "fig, axes = plt.subplots(figsize=(200,100), nrows=16, ncols=8)\n",
    "for i in range(16):\n",
    "    for j in range(8):\n",
    "        ax = axes[i][j]\n",
    "        ax.imshow((feature[(8*i)+j]).permute(1, 2, 0))\n",
    "        ax.title.set_text(' '.join('%5s' % os.path.basename(crop_dataset.imgs[(8*i)+j][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-18T12:32:45.978282Z",
     "iopub.status.busy": "2022-02-18T12:32:45.977989Z",
     "iopub.status.idle": "2022-02-18T12:33:37.681746Z",
     "shell.execute_reply": "2022-02-18T12:33:37.681009Z",
     "shell.execute_reply.started": "2022-02-18T12:32:45.978239Z"
    }
   },
   "outputs": [],
   "source": [
    "# Here we look at a single image. Our intent is to see how does an image transform through the convolution model that \n",
    "# we are proposing\n",
    "img_one_feature = feature[:1]\n",
    "img_one_label = label[:1]\n",
    "img_one_feature.shape, img_one_label.shape\n",
    "\n",
    "plt.imshow(img_one_feature[0].permute(1,2,0))\n",
    "\n",
    "# We define a convolution that converts the RGB channel into 6 features/filters/channels using a kernel size of 3 \n",
    "# a stride of 1 and padding of 1. On this we would apply pooling of 2*2\n",
    "cnv1 = nn.Conv2d(3, 6, kernel_size=9, padding=1, stride=1)\n",
    "#print(cnv1.weight, cnv1.bias)\n",
    "layer1 = cnv1(img_one_feature)\n",
    "fig, axes = plt.subplots(figsize=(200,100), ncols=6)\n",
    "for i in range(6):\n",
    "    x = torch.tensor(layer1[0,i:i+1,:], requires_grad=False)\n",
    "    ax = axes[i]\n",
    "    ax.imshow(x.permute(1, 2, 0))\n",
    "\n",
    "layer1 = F.relu(layer1)\n",
    "fig, axes = plt.subplots(figsize=(200,100), ncols=6)\n",
    "for i in range(6):\n",
    "    x = torch.tensor(layer1[0,i:i+1,:], requires_grad=False)\n",
    "    ax = axes[i]\n",
    "    ax.imshow(x.permute(1, 2, 0))\n",
    "\n",
    "pool = nn.MaxPool2d(2, 2)    \n",
    "layer1 = pool(layer1)\n",
    "fig, axes = plt.subplots(figsize=(200,100), ncols=6)\n",
    "for i in range(6):\n",
    "    x = torch.tensor(layer1[0,i:i+1,:], requires_grad=False)\n",
    "    ax = axes[i]\n",
    "    ax.imshow(x.permute(1, 2, 0))\n",
    "print()\n",
    "\n",
    "\n",
    "# We define a convolution that converts the RGB channel into 12 features/filters/channels using a kernel size of 3 \n",
    "# a stride of 1 and padding of 1. On this we would apply pooling of 2*2\n",
    "cnv2 = nn.Conv2d(6, 12, kernel_size=6, padding=1, stride=1)\n",
    "#print(cnv2.weight, cnv1.bias)\n",
    "layer2 = cnv2(layer1)\n",
    "fig, axes = plt.subplots(figsize=(200,100), ncols=12)\n",
    "for i in range(12):\n",
    "    x = torch.tensor(layer2[0,i:i+1,:], requires_grad=False)\n",
    "    ax = axes[i]\n",
    "    ax.imshow(x.permute(1, 2, 0))\n",
    "\n",
    "layer2 = F.relu(layer2)\n",
    "fig, axes = plt.subplots(figsize=(200,100), ncols=12)\n",
    "for i in range(12):\n",
    "    x = torch.tensor(layer2[0,i:i+1,:], requires_grad=False)\n",
    "    ax = axes[i]\n",
    "    ax.imshow(x.permute(1, 2, 0))\n",
    "\n",
    "pool = nn.MaxPool2d(2, 2)    \n",
    "layer2 = pool(layer2)\n",
    "fig, axes = plt.subplots(figsize=(200,100), ncols=12)\n",
    "for i in range(12):\n",
    "    x = torch.tensor(layer2[0,i:i+1,:], requires_grad=False)\n",
    "    ax = axes[i]\n",
    "    ax.imshow(x.permute(1, 2, 0))\n",
    "print()\n",
    "\n",
    "\n",
    "# We define a convolution that converts the RGB channel into 12 features/filters/channels using a kernel size of 3 \n",
    "# a stride of 1 and padding of 1. On this we would apply pooling of 2*2\n",
    "cnv3 = nn.Conv2d(12, 36, kernel_size=3, padding=1, stride=1)\n",
    "#print(cnv3.weight, cnv1.bias)\n",
    "layer3 = cnv3(layer2)\n",
    "fig, axes = plt.subplots(figsize=(200,100), ncols=12, nrows=3)\n",
    "for i in range(3):\n",
    "    for j in range(12):\n",
    "        x = torch.tensor(layer3[0,(12*i) + j: (12*i) + j + 1,:], requires_grad=False)\n",
    "        ax = axes[i][j]\n",
    "        ax.imshow(x.permute(1, 2, 0))\n",
    "\n",
    "layer3 = F.relu(layer3)\n",
    "fig, axes = plt.subplots(figsize=(200,100), ncols=12, nrows=3)\n",
    "for i in range(3):\n",
    "    for j in range(12):\n",
    "        x = torch.tensor(layer3[0,(12*i) + j: (12*i) + j + 1,:], requires_grad=False)\n",
    "        ax = axes[i][j]\n",
    "        ax.imshow(x.permute(1, 2, 0))\n",
    "\n",
    "pool = nn.MaxPool2d(2, 2)    \n",
    "layer3 = pool(layer3)\n",
    "fig, axes = plt.subplots(figsize=(200,100), ncols=12, nrows=3)\n",
    "for i in range(3):\n",
    "    for j in range(12):\n",
    "        x = torch.tensor(layer3[0,(12*i) + j: (12*i) + j + 1,:], requires_grad=False)\n",
    "        ax = axes[i][j]\n",
    "        ax.imshow(x.permute(1, 2, 0))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T17:32:49.956874Z",
     "iopub.status.busy": "2022-02-19T17:32:49.956399Z",
     "iopub.status.idle": "2022-02-19T17:32:49.966074Z",
     "shell.execute_reply": "2022-02-19T17:32:49.965409Z",
     "shell.execute_reply.started": "2022-02-19T17:32:49.956837Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now create a a model that can be trained for disease detection\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 9)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 12, 6)\n",
    "        self.conv3 = nn.Conv2d(12, 18, 3)\n",
    "        self.fc1 = nn.Linear(18 * 28 * 28, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 512)\n",
    "        self.fc4 = nn.Linear(512, 38)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T10:07:25.939758Z",
     "iopub.status.busy": "2022-02-19T10:07:25.939462Z",
     "iopub.status.idle": "2022-02-19T10:07:26.465979Z",
     "shell.execute_reply": "2022-02-19T10:07:26.465248Z",
     "shell.execute_reply.started": "2022-02-19T10:07:25.939727Z"
    }
   },
   "outputs": [],
   "source": [
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T10:07:31.758026Z",
     "iopub.status.busy": "2022-02-19T10:07:31.757298Z",
     "iopub.status.idle": "2022-02-19T10:07:31.772112Z",
     "shell.execute_reply": "2022-02-19T10:07:31.771421Z",
     "shell.execute_reply.started": "2022-02-19T10:07:31.75798Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in net.state_dict():\n",
    "    print(param_tensor, \"\\t\", net.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T10:07:34.43893Z",
     "iopub.status.busy": "2022-02-19T10:07:34.438671Z",
     "iopub.status.idle": "2022-02-19T10:07:34.446414Z",
     "shell.execute_reply": "2022-02-19T10:07:34.445573Z",
     "shell.execute_reply.started": "2022-02-19T10:07:34.438901Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T10:07:36.881862Z",
     "iopub.status.busy": "2022-02-19T10:07:36.881612Z",
     "iopub.status.idle": "2022-02-19T10:07:36.923358Z",
     "shell.execute_reply": "2022-02-19T10:07:36.922426Z",
     "shell.execute_reply.started": "2022-02-19T10:07:36.881834Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T10:07:39.614309Z",
     "iopub.status.busy": "2022-02-19T10:07:39.614042Z",
     "iopub.status.idle": "2022-02-19T10:07:42.998924Z",
     "shell.execute_reply": "2022-02-19T10:07:42.998193Z",
     "shell.execute_reply.started": "2022-02-19T10:07:39.61428Z"
    }
   },
   "outputs": [],
   "source": [
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T10:09:45.716849Z",
     "iopub.status.busy": "2022-02-19T10:09:45.716133Z",
     "iopub.status.idle": "2022-02-19T11:05:03.228966Z",
     "shell.execute_reply": "2022-02-19T11:05:03.227418Z",
     "shell.execute_reply.started": "2022-02-19T10:09:45.71681Z"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    net.train()\n",
    "    for i, data in enumerate(crop_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        if i % 100 == 99:\n",
    "            print(f'Processed {i} batch of 128 images')\n",
    "            \n",
    "        if i % 500 == 499:    # print every 2000 mini-batches\n",
    "            accu=100.*correct/total\n",
    "            \n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 500:.3f} accuracy:{accu:.3f}')\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T11:07:02.107362Z",
     "iopub.status.busy": "2022-02-19T11:07:02.106729Z",
     "iopub.status.idle": "2022-02-19T11:07:02.742162Z",
     "shell.execute_reply": "2022-02-19T11:07:02.741433Z",
     "shell.execute_reply.started": "2022-02-19T11:07:02.10723Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"cropdisease.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T17:32:56.245900Z",
     "iopub.status.busy": "2022-02-19T17:32:56.245410Z",
     "iopub.status.idle": "2022-02-19T17:33:02.523616Z",
     "shell.execute_reply": "2022-02-19T17:33:02.522837Z",
     "shell.execute_reply.started": "2022-02-19T17:32:56.245860Z"
    }
   },
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load('../input/modelcropdisease/cropdisease.pth'))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T17:33:02.525469Z",
     "iopub.status.busy": "2022-02-19T17:33:02.525137Z",
     "iopub.status.idle": "2022-02-19T17:33:08.017451Z",
     "shell.execute_reply": "2022-02-19T17:33:08.016745Z",
     "shell.execute_reply.started": "2022-02-19T17:33:02.525431Z"
    }
   },
   "outputs": [],
   "source": [
    "# Here we create our final transformation that would be used before we send the data for training the model\n",
    "transform = torchvision.transforms.Compose([transforms.ToTensor(), \\\n",
    "                                            transforms.Normalize((0.4743617, 0.49847862, 0.4265874 ), \\\n",
    "                                                                 (0.21134755, 0.19044809, 0.22679578))\n",
    "                                           ]\n",
    "                                          )\n",
    "test_dataset = torchvision.datasets.ImageFolder('../input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid', transform=transform)\n",
    "test_dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T17:33:11.519269Z",
     "iopub.status.busy": "2022-02-19T17:33:11.518976Z",
     "iopub.status.idle": "2022-02-19T17:33:11.522843Z",
     "shell.execute_reply": "2022-02-19T17:33:11.522167Z",
     "shell.execute_reply.started": "2022-02-19T17:33:11.519240Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now we can create a loader that will help us load images in batches for training purpose \n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T17:33:16.194652Z",
     "iopub.status.busy": "2022-02-19T17:33:16.194132Z",
     "iopub.status.idle": "2022-02-19T17:33:17.358748Z",
     "shell.execute_reply": "2022-02-19T17:33:17.358016Z",
     "shell.execute_reply.started": "2022-02-19T17:33:16.194618Z"
    }
   },
   "outputs": [],
   "source": [
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "print(images[0:4,:,:].shape)\n",
    "grid_image = torchvision.utils.make_grid(images[0:4,:,:], nrow=1)\n",
    "print(grid_image.shape)\n",
    "plt.imshow(grid_image.permute(1, 2, 0))\n",
    "print('GroundTruth: ', ' '.join(f'{labels[j]:5d}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T17:33:25.915638Z",
     "iopub.status.busy": "2022-02-19T17:33:25.914903Z",
     "iopub.status.idle": "2022-02-19T17:39:56.766432Z",
     "shell.execute_reply": "2022-02-19T17:39:56.765689Z",
     "shell.execute_reply.started": "2022-02-19T17:33:25.915600Z"
    }
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T17:59:02.614330Z",
     "iopub.status.busy": "2022-02-19T17:59:02.614006Z",
     "iopub.status.idle": "2022-02-19T18:04:46.303377Z",
     "shell.execute_reply": "2022-02-19T18:04:46.302644Z",
     "shell.execute_reply.started": "2022-02-19T17:59:02.614297Z"
    }
   },
   "outputs": [],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {value:0 for key, value in test_dataset.class_to_idx.items()}\n",
    "total_pred = {value:0 for key, value in test_dataset.class_to_idx.items()}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[int(label)] += 1\n",
    "            total_pred[int(label)] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for key, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[key]\n",
    "    print(f'Accuracy for class: {key:5d} is {accuracy:.1f} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
